{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73680d28-70d7-44bb-9978-7774f5eebf04",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 7 - Model Based Reinforcement Learning </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Sep 4, 2023 - Nov 30, 2023</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. MCTS </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "    \n",
    "<a href='#Q1'><b>Student Question 1</b> Difficulty of the task (10 points)</a>\\\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing MCTS (30 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 2</b> MCTS phases</a>\n",
    "    \n",
    "**Total Points:** 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74a17-1c90-4f6b-90ea-d3164caf99a1",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "In this section, we will use **Monte Carlo Tree Search (MCTS)** algorithm to solve **DeepSea** environment form [Behaviour Suite for Reinforcement Learning (bsuite)](https://github.com/google-deepmind/bsuite). The environment targets the challenge of exploration and represents a N√óN grid where the agent starts in the top left and has to reach a goal in the bottom right location. At each timestep, the agent moves one row down and can choose one out of two actions. The agent observes the current location and receives a small negative reward of -0.01/N  for moving right and 0 reward for moving left. Additionally, the agent receives a reward of +1 for reaching the goal (treasure) and the episode ends after N timesteps. In this exercise, the number of rows and columns (N) is 10. \n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/deep_sea.png\" width=\"400px\">\n",
    "    <figcaption> Figure 1: Deep-Sea environment </figcaption>\n",
    "</div>\n",
    "\n",
    "## 1.1 Learning Objectives: <a id='1.1'></a>\n",
    "- Understand different phases of MCTS\n",
    "- Implement a simplified version of MCTS\n",
    "\n",
    "## 1.2 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "You don‚Äôt have to edit any other file other than ```ex7.ipynb``` to complete this exercise.\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                 # Images used in notebook\n",
    "‚îÇ   ex7_MCTS.ipynb       # Main assignment file containing tasks <---------\n",
    "‚îÇ   env.py               # Wrappers for the environment\n",
    "‚îÇ   simulator.py         # Using the exact environment as the model (simulator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54855efc-e89b-4386-938b-d6f4bf052f98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.</b> Difficulty of the task (10 points)</h3> \n",
    "\n",
    "1.1. What is the probability of reaching the goal state (a function of N) for **DeepSea** environment? <br>\n",
    "1.2. If N is large, DQN (with the $\\epsilon$-greedy policy) usually fail to reach the goal state (in fact, N=10 is already challenging for DQN). In this case, which strategy will DQN converge to? <br>\n",
    "            \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "    üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58072844-b0c4-49f2-bf7b-b4384a4e8959",
   "metadata": {},
   "source": [
    "- 1.1 From the description: The environment targets the challenge of exploration and represents\n",
    "a N√óN grid where the agent starts in the top left and has to reach a goal in the bottom right location. At\n",
    "each timestep, the agent moves one row down and can choose one out of two actions. So for each time step, the agent has two choice, resulting in total $2^N$ different paths. Because there is only one path to lead to the treasure (top-left bottom right diagonal), the probability of reaching the goal state as a function of N is therefore $\\dfrac{1}{2^N}$.\n",
    "\n",
    "- 1.2 Even though going right will help the agent head towards the goal, it will penalize the agent a little bit. Since DQN cannot foresee the treasure, its strategy will converge to just going left to avoid being penalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce37baa-7700-4167-b96b-5e65c990a881",
   "metadata": {},
   "source": [
    "# 2. MCTS <a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081edfa-3417-44f7-9144-80cc5af076c7",
   "metadata": {},
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implement MCTS algorithm (30 points) </h3> \n",
    "\n",
    "Complete ```TODOs``` in the MCTS class below. Specifically, you need to: <br>\n",
    "1. finish the implementation of ```select_action``` method that selects the best action given the MCTS node using UCB1 exploration. <br>\n",
    "2. implement ```simulation``` method where you need to use best action to select the next node and expansion procedure of MCTS when there are no children.\n",
    "3. complete ```backpropagation``` method that updates the attributes of each node in the trajectory. <br>\n",
    "\n",
    "**Ensure that the notebook contains the average return plot.**\n",
    "\n",
    "The reference training plot is as Figure 2 (your plot might look different):\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/mcts_avg_return.png\">\n",
    "    <figcaption> Figure 2: Average episode return for MCTS on DeepSea environment </figcaption>\n",
    "</div>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11df358-d684-4d7c-b8ee-d6b3f89258a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bsuite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import BsuiteToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073067c6-6b04-4af9-954d-c1deb58fa1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### MCTS #####\n",
    "class Node(object):\n",
    "    \"\"\" A MCTS Node. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reward: float = 0.\n",
    "        self.visit_count: int = 0\n",
    "        self.done: bool = False\n",
    "        self.total_value: float = 0.  # cumulative value\n",
    "        self.children: dict = {}  # children nodes, index is the action\n",
    "\n",
    "    def expand(self, num_action: int):\n",
    "        \"\"\" Expands this node by adding cild nodes. \"\"\"\n",
    "        for action in range(num_action):\n",
    "            self.children[action] = Node()\n",
    "    \n",
    "    @property\n",
    "    def value(self):  # Q(s, a)\n",
    "        \"\"\"Returns the value of this node.\"\"\"\n",
    "        if self.visit_count:\n",
    "            return self.total_value / self.visit_count\n",
    "        return 0.\n",
    "\n",
    "    @property\n",
    "    def children_visits(self) -> np.ndarray:\n",
    "        \"\"\"Return array of visit counts of visited children.\"\"\"\n",
    "        return np.array([c.visit_count for c in self.children.values()])\n",
    "\n",
    "    @property\n",
    "    def children_values(self) -> np.ndarray:\n",
    "        \"\"\"Return array of values of visited children.\"\"\"\n",
    "        return np.array([c.value for c in self.children.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bccd58bf-c6aa-4cd9-a6a4-5170018f0fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    def __init__(self, env, discount = 1):\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount = discount\n",
    "        self.init_node = Node()\n",
    "        \n",
    "    def select_action(self, node, scale=1):\n",
    "        # TODO: implement selection phase of MCTS algorithm and return the best action.\n",
    "        # Hints:\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        #     2.1. Compute Q-value and UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "        #     2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "        #     2.3. Select the best action using results from 2.2.\n",
    "        ########## Your code starts here. ##########\n",
    "\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        if not node.children:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        \n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        else:\n",
    "            best_value = -float('inf')\n",
    "            best_action = None\n",
    "            total_visits = sum(child.visit_count for child in node.children.values())\n",
    "            for action, child in node.children.items():\n",
    "                # 2.1. Compute Q-value \n",
    "                Q_value = child.value\n",
    "                # 2.1. Compute UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "                UCB1 = np.sqrt(np.log(total_visits) / (1 + child.visit_count))\n",
    "                # 2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "                node_value = Q_value + scale * UCB1\n",
    "                # 2.3. Select the best action using results from 2.2.\n",
    "                if node_value > best_value:\n",
    "                    best_value = node_value\n",
    "                    best_action = action\n",
    "            return best_action \n",
    "        \n",
    "        ########## Your code ends here. ##########\n",
    "        \n",
    "    def simulation(self):\n",
    "        state = self.env.reset()\n",
    "        node = self.init_node\n",
    "        trajectory = [node]\n",
    "\n",
    "        while not node.done:\n",
    "            # TODO: perform simulation phase of MCTS and return the trajectory of MCTS nodes.\n",
    "            # Hints:\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            # 5. Add node to the trajectory list.\n",
    "            ########## Your code starts here. ##########\n",
    "\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            best_action = self.select_action(node)\n",
    "            \n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            next_state, reward, done, _ = self.env.step(best_action)\n",
    "            \n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            if best_action not in node.children:\n",
    "                node.expand(self.num_actions)\n",
    "            \n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            node = node.children[best_action]\n",
    "            \n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            node.reward = reward\n",
    "            node.done = done\n",
    "            \n",
    "            # 5. Add node to the trajectory list.\n",
    "            trajectory.append(node)\n",
    "            \n",
    "            ########## Your code ends here. ##########\n",
    "            \n",
    "\n",
    "            \n",
    "        return trajectory\n",
    "\n",
    "    def backpropagation(self, trajectory):\n",
    "        ep_return = 0\n",
    "        while trajectory:\n",
    "            node = trajectory.pop()\n",
    "            # TODO: implement backpropagation phase of MCTS and return the discounted sum of rewards\n",
    "            # Hints:\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            # 2. Add node return to episode return. \n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            ########## Your code starts here. ##########\n",
    "\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            ep_return = self.discount * ep_return + node.reward\n",
    "        \n",
    "            # 2. Add node return to episode return.\n",
    "            node.total_value += ep_return\n",
    "        \n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            node.visit_count += 1\n",
    "            \n",
    "            ########## Your code ends here. ##########\n",
    "        \n",
    "        return ep_return\n",
    "\n",
    "    def run(self, num_iteration):\n",
    "        returns = []\n",
    "        for iter in range(num_iteration):\n",
    "            trajectory = self.simulation()\n",
    "            episode_return = self.backpropagation(trajectory)\n",
    "            returns.append(episode_return)\n",
    "            \n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67408669-c97e-446b-8517-390586caae54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[97mLoaded bsuite_id: deep_sea/0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = bsuite.load_from_id('deep_sea/0')\n",
    "env = BsuiteToGymWrapper(env)\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d91f7c-db90-4d15-817a-1896fed87c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = MCTS(env)\n",
    "returns = agent.run(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82a7c24-a9b6-4806-a89c-22af633d821b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computes average of last 50 episodes\n",
    "avg_returns = [np.mean(returns[-50+i:i]) for i in range(50, num_episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b11ba409-146d-4a2a-83cc-a7877c3a5126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(avg_returns, linewidth=1.2, color='b')\n",
    "plt.xlabel('Episodes', fontsize=10)\n",
    "plt.ylabel('Return', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8d5d7-d6c4-4b95-98e0-cfde0fbba0c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 2.</b> MCTS algorithm (5 points)</h3> \n",
    "Describe different phases in MCTS. Explain each one briefly in your own words.\n",
    "<br>\n",
    "<br>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a8cfe-403a-4551-beb0-f54068353527",
   "metadata": {
    "tags": []
   },
   "source": [
    "Monte Carlo Tree Search (MCTS) consists of 4 steps:\n",
    "\n",
    "**1. Selection**:\n",
    "\n",
    "Starting from the root node, the selection step begins to traverse through the tree by selecting the children nodes iteratively. The selection strategy tries to balance the exploration of less-visited nodes and the exploitation of nodes with highest estimated rewards. Common algorithms to select non-leaf nodes include the Upper Confidence Bound for Trees (UCT) and the PUCT algorithm (used in AlphaZero).\n",
    "\n",
    "**2. Expansion**:\n",
    "\n",
    "When MCTS reaches a leaf node provided that it is not terminal node, new child nodes are appended to this leaf, where each child node represents a possible action that can be taken from the current state. \n",
    "\n",
    "**3. Simulation**:\n",
    "\n",
    "After expansion, a trajectory is simulated from the newly expanded node's state. This simulation follows a policy modeled by any heuristics, such as neural networks in AlphaZero to predict the task outcome until a terminal state or certain depth is reached.\n",
    "\n",
    "**4. Backpropagation**:\n",
    "\n",
    "After simulation completes, the outcome result is backpropagated through all trajectories that have arrive at the leaf node, up until the root node. The update works by incrementing the visiting counts and adjusting the estimated value of each node. After backpropagation, the tree is updated, and the whole process restarts from selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659d502-725a-41f7-a1ad-fac876681fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex7_MCTS.ipynb```) are answered and the relevant plots are recorded in the relevant places. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e45412-1af0-4524-baba-548e88ad4992",
   "metadata": {},
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364da21-6c7f-4c68-b35a-e308b3f1acff",
   "metadata": {},
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47684b1f-c2de-42d5-9eba-56ebe6ab4924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286772-df2e-4e9d-a783-24acdcbcbbd2",
   "metadata": {},
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a41a89e6-b33d-4f38-b169-6e871041c15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T1 = 5 # Student Task 1. Implementing MCTS\n",
    "Q1 = 4 # Question 1.1: Difficulty of the task\n",
    "Q2 = 3 # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00739461-6f94-43d6-a65a-9a509d061340",
   "metadata": {},
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a12a922-a3d4-4297-b1a1-e5819a946949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T1 = 5 # Student Task 1. Implementing MCTS\n",
    "Q1 = 4 # Question 1.1: Difficulty of the task\n",
    "Q2 = 4 # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f95cba-7e62-4cda-b058-8134b4daa09f",
   "metadata": {},
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "And other feedback you think is worth including. Type in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d377ce6-e562-4472-a72d-54748c6c0fd9",
   "metadata": {},
   "source": [
    "MCTS can be applied in my research in materials science to efficient find the vast space of potential material compositions and structures. I also believe that MCTS can predict model material behaviors under different conditions to use optimal materials for their specialized applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a57ceb-9879-448b-bdc8-a38af34da4f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Please use the following section to record references.\n",
    "# References <a id='4.'></a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
