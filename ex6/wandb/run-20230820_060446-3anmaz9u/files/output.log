{'seed': 408, 'exp_name': 'ex6_task2', 'run_id': 1692500684, 'testing': False, 'model_path': PosixPath('/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/results/HalfCheetah-v4/model/HalfCheetah-v4_params.pt'), 'save_video': False, 'save_logging': True, 'save_model': True, 'use_wandb': True, 'silent': False, 'run_suffix': 0, 'env_name': 'HalfCheetah-v4', 'agent_name': 'ddpg', 'train_episodes': 2000, 'gamma': 0.99, 'lr': 0.0005, 'batch_size': 100, 'buffer_size': 1000000.0, 'tau': 0.005}
{'ep': 0, 'timesteps': 1000, 'ep_reward': -181.4715253300843}
Traceback (most recent call last):
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/train.py", line 172, in <module>
    main()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/train.py", line 145, in main
    train_info = train(agent, env)
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/train.py", line 56, in train
    info = agent.update()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/ddpg.py", line 74, in update
    info = self._update()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex6/ddpg.py", line 107, in _update
    actor_loss.backward()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt