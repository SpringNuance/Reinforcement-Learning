
{'ep': 0, 'logstd': array([[0.]], dtype=float32), 'timesteps': 4, 'ep_reward': 4.0, 'episodes': 0}
{'ep': 100, 'logstd': array([[0.]], dtype=float32), 'timesteps': 11, 'ep_reward': 11.0, 'episodes': 100}
{'ep': 200, 'logstd': array([[0.]], dtype=float32), 'timesteps': 43, 'ep_reward': 43.0, 'episodes': 200}
{'ep': 300, 'logstd': array([[0.]], dtype=float32), 'timesteps': 76, 'ep_reward': 76.0, 'episodes': 300}
{'ep': 400, 'logstd': array([[0.]], dtype=float32), 'timesteps': 12, 'ep_reward': 12.0, 'episodes': 400}
{'ep': 500, 'logstd': array([[0.]], dtype=float32), 'timesteps': 49, 'ep_reward': 49.0, 'episodes': 500}
{'ep': 600, 'logstd': array([[0.]], dtype=float32), 'timesteps': 10, 'ep_reward': 10.0, 'episodes': 600}
Traceback (most recent call last):
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex5/train.py", line 171, in <module>
    main()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex5/train.py", line 148, in main
    train_info = train(agent, env)
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex5/train.py", line 57, in train
    info = agent.update()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/ex5/agent.py", line 117, in update
    self.optimizer.step()
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 269, in wrapper
    with torch.autograd.profiler.record_function(profile_name):
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/torch/autograd/profiler.py", line 492, in __enter__
    self.record = torch.ops.profiler._record_function_enter_new(self.name, self.args)
  File "/m/home/home5/51/nguyenb5/unix/Reinforcement-Learning/venv/lib/python3.10/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
KeyboardInterrupt